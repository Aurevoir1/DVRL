# 基于强化学习发的样本蒸馏技术

## 谷歌代码阅读  （Baseline）

>  main_dvrl_image_transformer_learning.py

### import

- argparse -- 控制台参数设定
- numpy
- sklearn- linear_model
- Tensorflow
- keras、applications、layers、models
- data_loading -- 数据加载py
- dvrl -- 算法py
- dvrl_metrics -- 算法性能度量py

### Args

- data_name数据集名称
- train_no训练数据编号
- valid_no验证数据编号
- noise_rate噪声比率
- normalization标准化
- network parameters神经网络参数

### 代码块

```python
基本参数确定
# Data name (either cifar10 or cifar100)
data_name = args.data_name

# The number of training and validation samples
dict_no = dict()
dict_no['train'] = args.train_no
dict_no['valid'] = args.valid_no
dict_no['test'] = args.test_no

# Additional noise ratio  附加噪声比
noise_rate = args.noise_rate

# Checkpoint file name   Checkpoint文件
checkpoint_file_name = args.checkpoint_file_name
```

​	tf.keras.applications.inception_v3.preprocess_input  是keras针对**<u>输入图像数据的预处理函数</u>**  输出的事float32格式的array或者tensor

```python
# Inception_v3函数对输入的图像进行预处理  输出  float32 的 array 或者 tensor，值域在 -1 ~ 1 间
preprocess_function = applications.inception_v3.preprocess_input
input_shape = (299, 299)
```

```python
def encoder_model(architecture='inception_v3', pre_trained_dataset='imagenet',
                  downsample_factor=8):
  """Returns encoder model.
  编码模型
  Defines the encoder model to learn the representations for image dataset.
  In this example, we are considering the InceptionV3 model trained on
  ImageNet dataset, followed by simple average pooling-based downsampling.
  定义encoder model 来学习图像数据的表示  在这个例子中，我们使用InceptionV3模型在图像数据集上训练，跟随 平均池化下采样过程
  Args:参数列表
    architecture: Base architecture of encoder model (e.g. 'inception_v3')
    pre_trained_dataset: The dataset used to pre-train the encoder model 预训练encoder model的数据集
    downsample_factor: Downsample factor for the outputs  输出的下采样特征

  Raises:
    NameError: Returns name errors if architecture is not 'inception_v3'
  """
  tf_input = layers.Input(shape=(input_shape[0], input_shape[1], 3))  # 输入
  if architecture == 'inception_v3':  # encoder model的结构为 inceptionV3
    model = applications.inception_v3.InceptionV3(
        input_tensor=tf_input, weights=pre_trained_dataset, include_top=False)
    output_pooled = layers.AveragePooling2D((downsample_factor, downsample_factor),
                           strides=(downsample_factor, downsample_factor))(model.output) # 池化
  else:
    raise NameError('Invalid architecture')
  return models.Model(model.input, output_pooled)  # 返回的是encoder后的model
```

各个部分进行编码    

- 训练样本、验证集、测试集都进行编码   使用的data_loading中的encode_image方法

```python
# Encodes training samples  训练样本编码
enc_x_train = data_loading.encode_image(x_train,
                              encoder_model,
                              input_shape,
                              preprocess_function)
# Encodes validation samples  验证样本编码
enc_x_valid = data_loading.encode_image(x_valid,
                              encoder_model,
                              input_shape,
                              preprocess_function)
# Encodes testing samples   测试样本编码
enc_x_test = data_loading.encode_image(x_test,
                              encoder_model,
                              input_shape,
                              preprocess_function)
```

定义预测模型

```python
# Defines predictive model  定义预测模型  
pred_model = keras.models.Sequential()
pred_model.add(keras.layers.Dense(len(set(y_train)), activation='softmax'))  # 全连接层
pred_model.compile(optimizer='adam', loss='categorical_crossentropy',  
                   metrics=['accuracy'])  # 优化器使用Adam  损失函数是交叉熵损失函数
```

初始化DVRL   调用dvrl.py中的Dvrl类  初始化一个DVRL  并进行训练  

```python
# Initalizes DVRL  初始化DVRL
dvrl_class = dvrl.Dvrl(enc_x_train, y_train, enc_x_valid, y_valid,
                       problem, pred_model, parameters,
                       checkpoint_file_name, flags)  # 将相关参数传入Dvrl中

# Trains DVRL
dvrl_class.train_dvrl('accuracy')

print('Finished DVRL training.')
```

输出DVRL的结果是  数据价值   

dve_out就是dat valuation之后的结果

```python
# Outputs 输出
# Data valuation   数据价值
dve_out = dvrl_class.data_valuator(enc_x_train, y_train)

print('Finished data valuation.')
```

评价模型  使用LogisticRegression

- 逻辑回归 -  解决二分类中的线性可分的部分问题
- 参数列表：
  - solver  损失函数的迭代计算方法：
    - ‘newton-cg’  使用牛顿法
    - ‘lbfgs’ 使用L-BFGS拟牛顿法
    - ‘liblinear’：使用liblinear
    - ‘sag’  使用 Stochastic Average Gradient descent 算法
  - multi_class  多类别分类策略
    - ‘ovr’:采用one-vs-rest策略进行多分类
    - ‘multinomial’：直接采用多分类逻辑回归模型
  - max_iter:最大迭代次数

```python
# Evaluations   评估
# Evaluation model   评价模型
eval_model = linear_model.LogisticRegression(solver='lbfgs',
                                             multi_class='auto',
                                             max_iter=2000)
```



> data_loading.py
>

加载 图片 数据集部分

```python
def load_image_data(data_name, dict_no, noise_rate):
    """Loads image datasets.  加载图片数据集的方法
    This module loads CIFAR10 and CIFAR100 datasets and
    saves train.npz, valid.npz and test.npz files under data_files directory.
    If noise_rate > 0.0, adds noise on the datasets.
    Args:
      data_name: 'cifar10' or 'cifar100'
      dict_no: Training and validation set numbers
      noise_rate: Label corruption ratio
    Returns:
      noise_idx: Indices of noisy samples  损坏样本指数
    """

    # Loads datasets
    if data_name == 'cifar10':
        (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()
    elif data_name == 'cifar100':
        (x_train, y_train), (x_test, y_test) = datasets.cifar100.load_data()

    # Splits train, valid and test sets
    train_idx = np.random.permutation(len(x_train))  # permutation函数将len长度的list随机排序

    valid_idx = train_idx[:dict_no['valid']]
    train_idx = train_idx[dict_no['valid']:(dict_no['train'] + dict_no['valid'])]

    test_idx = np.random.permutation(len(x_test))[:dict_no['test']]

    x_valid = x_train[valid_idx]
    x_train = x_train[train_idx]
    x_test = x_test[test_idx]

    y_valid = y_train[valid_idx].flatten()  # flatten函数将array降为 1 维
    y_train = y_train[train_idx].flatten()
    y_test = y_test[test_idx].flatten()

    # Adds noise on labels  添加噪声
    y_train, noise_idx = dvrl_utils.corrupt_label(y_train, noise_rate)

    # Saves data
    if not os.path.exists('data_files'):
        os.makedirs('data_files')

    np.savez_compressed('./data_files/train.npz',
                        x_train=x_train, y_train=y_train)
    np.savez_compressed('./data_files/valid.npz',
                        x_valid=x_valid, y_valid=y_valid)
    np.savez_compressed('./data_files/test.npz',
                        x_test=x_test, y_test=y_test)

    return noise_idx
```

图像编码部分 encode_image

```python
def encode_image(features, encoder_model, input_shape, preprocess_function,
                 batch_size=16):
    """Encodes images using pre-trained encoder model.  使用预训练encoder model来给图像编码
    We apply encoding step with a pre-trained model and save the encoded
    representation to input them
    directly to DVRL, for computational efficiency.  将encoded表示直接输入给DVRL  来获得高效的计算
    Args:
      features: Input image
      encoder_model: Model for encoding images (e.g., InceptionV3)  图像预处理函数-InceptionV3
      input_shape: Input shape of the encoder model
      preprocess_function: Preprocessing function from features to input_shape of
                           encoder_model
      batch_size: Number of mini-batches for encoding images
    Returns:
      encoded_features: Encoded images
    """

    ## Number of samples
    n_features = len(features)  # 输入image的len

    # Placeholder for batch of images
    batch_of_images_placeholder = tf.placeholder('uint8',
                                                 (None, features.shape[1],
                                                  features.shape[2],
                                                  features.shape[3]))
    # 使用tf.image.resize_images  调整输入图片的尺寸大小
    tf_resize_op = tf.image.resize_images(batch_of_images_placeholder,
                                          input_shape, method=0)

    # Data extraction function  数据提取函数
    def data_generator(sess, data):
        """Generates preprocessed data.  生成预处理的data   一个batch一个batch的加工
        Args:
          sess: Session
          data: Image data
        Returns:
          generator: Generator function
        """

        def generator():
            """Subfunction of data generator in the session.  session中数据生成器的子程序
            Yields:
              batch_of_image_preprocessed: preprocessed data  预处理数据
            """
            start = 0
            end = start + batch_size  # 一个batch的长度
            n = data.shape[0]
            while True:
                batch_of_images_resized = sess.run(tf_resize_op,
                                                   {batch_of_images_placeholder:
                                                        data[start:end]})  # 一个batch中resized过的image
                batch_of_images__preprocessed = \
                    preprocess_function(batch_of_images_resized)  # 使用预处理函数将图片进行加工
                start = start + batch_size
                end = end + batch_size # 向后推移一个batch
                if start >= n:
                    start = 0
                    end = batch_size
                yield batch_of_images__preprocessed

        return generator
```

进行图像encode

```python
with tf.Session() as sess:

    backend.set_session(sess)
    model = encoder_model()
    data_gen = data_generator(sess, features)
    ftrs_training = model.predict_generator(data_gen(),
                                            n_features / batch_size,
                                            verbose=1)

encoded_features = \
    np.array([ftrs_training[i].flatten() for i in range(n_features)])

return encoded_features
```

> dvrl.py



